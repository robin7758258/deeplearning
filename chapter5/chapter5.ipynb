{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#5章誤差逆伝播法\n",
    "#5.4単純なレイヤの実装\n",
    "#5.4.1乗算レイヤの実装\n",
    "class MulLayer:\n",
    "    def __init__(self):\n",
    "        self.x=None\n",
    "        self.y=None\n",
    "        \n",
    "    def forward(self,x,y):\n",
    "        self.x=x\n",
    "        self.y=y\n",
    "        out=x*y\n",
    "        return out\n",
    "    \n",
    "    def backward(self,dout):\n",
    "        dx=dout*self.y #xとyをひっくり返す\n",
    "        dy=dout*self.x\n",
    "        return dx,dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220.00000000000003\n"
     ]
    }
   ],
   "source": [
    "apple=100\n",
    "apple_num=2\n",
    "tax=1.1\n",
    "\n",
    "#layer\n",
    "mul_apple_layer=MulLayer()  \n",
    "mul_tax_layer=MulLayer()\n",
    "\n",
    "#forward\n",
    "apple_price=mul_apple_layer.forward(apple,apple_num)\n",
    "price=mul_tax_layer.forward(apple_price,tax)\n",
    "\n",
    "print(price)#220"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2 110.00000000000001 200\n"
     ]
    }
   ],
   "source": [
    "#backward\n",
    "dprice=1\n",
    "dapple_price,dtax=mul_tax_layer.backward(dprice)\n",
    "dapple,dapple_num=mul_apple_layer.backward(dapple_price)\n",
    "print(dapple,dapple_num,dtax)#2.2 110 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.4.2加算レイヤの実装\n",
    "class AddLayer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self,x,y):\n",
    "        out=x+y\n",
    "        return out\n",
    "    \n",
    "    def backward(self,dout):\n",
    "        dx=dout*1\n",
    "        dy=dout*1\n",
    "        return dx,dy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple=100\n",
    "apple_num=2\n",
    "orange=150\n",
    "orange_num=3\n",
    "tax=1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#layer\n",
    "mul_apple_layer=MulLayer()\n",
    "mul_orange_layer=MulLayer()\n",
    "add_apple_orange_layer=AddLayer()\n",
    "mul_tax_layer=MulLayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forward\n",
    "apple_price=mul_apple_layer.forward(apple,apple_num)\n",
    "orange_price=mul_orange_layer.forward(orange,orange_num)\n",
    "all_price=add_apple_orange_layer.forward(apple_price,orange_price)\n",
    "price=mul_tax_layer.forward(all_price,tax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#backward\n",
    "dprice=1\n",
    "dall_price,dtax=mul_tax_layer.backward(dprice)\n",
    "dapple_price,dorange_price=add_apple_orange_layer.backward(dall_price)\n",
    "dorange,dorange_num=mul_orange_layer.backward(dorange_price)\n",
    "dapple,dapple_num=mul_apple_layer.backward(dapple_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "715.0000000000001\n110.00000000000001 2.2 3.3000000000000003 165.0 650\n"
     ]
    }
   ],
   "source": [
    "print(price)\n",
    "print(dapple_num,dapple,dorange,dorange_num,dtax)#110 2.2 3.3 165 650"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.5活性化関数レイヤの実装\n",
    "#5.5.1ReLUレイヤ\n",
    "class Relu:\n",
    "    def __init__(self):\n",
    "        self.mask=None\n",
    "        \n",
    "    def forward(self,x):\n",
    "        self.mask=(x<=0)\n",
    "        out=x.copy()\n",
    "        out[self.mask]=0\n",
    "        return out\n",
    "    \n",
    "    def backward(self,dout):\n",
    "        dout[self.mask]=0\n",
    "        dx=dout\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  -0.5]\n [-2.   3. ]]\n"
     ]
    }
   ],
   "source": [
    "x=np.array([[1.0,-0.5],[-2.0,3.0]])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False  True]\n [ True False]]\n"
     ]
    }
   ],
   "source": [
    "mask=(x<=0)\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.5.2 Sigmoidレイヤ\n",
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.out=None\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out=1/(1+np.exp(-x))\n",
    "        self.out=out\n",
    "        return out\n",
    "    \n",
    "    def backward(self,dout):\n",
    "        dx=dout*(1.0-self.out)*self.out\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.6 Affine/Softmaxレイヤの実装\n",
    "#5.6.1 Affineレイヤ\n",
    "X=np.random.rand(2)#入力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "W=np.random.rand(2,3)#重み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "B=np.random.rand(3)#バイアス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape #(2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape#(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.shape#(3,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=np.dot(X,W)+B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.6.2 バッチ版Affineレイヤ\n",
    "X_dot_W=np.array([[0,0,0],[10,10,10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "B=np.array([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0],\n       [10, 10, 10]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dot_W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3],\n       [11, 12, 13]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dot_W+B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dY=np.array([[1,2,3,],[4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n       [4, 5, 6]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dB=np.sum(dY,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 7, 9])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Affine:\n",
    "    def __init__(self,W,b):\n",
    "        self.W=W\n",
    "        self.b=b\n",
    "        self.x=None\n",
    "        self.dW=None\n",
    "        self.db=None\n",
    "        \n",
    "    def forward(self,x):\n",
    "        self.x=x\n",
    "        out=np.dot(x,self.W)+self.b\n",
    "        return out\n",
    "    \n",
    "    def backward(self,dout):\n",
    "        dx=np.dot(dout,self.W.T)\n",
    "        self.dW=np.dot(self.x.T,dout)\n",
    "        self.db=np.sum(dout,axis=0)\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.6.3 Softmax-with-Lossレイヤ\n",
    "class SoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.loss=None #損失\n",
    "        self.y=None #softmaxの出力\n",
    "        self.t=None #教師データ(one-hot vector)\n",
    "        \n",
    "    def forward(self,x,t):\n",
    "        self.t=t\n",
    "        self.y=softmax(x)\n",
    "        self.loss=cross_entropy_error(self.y,self.t)\n",
    "        return self.loss\n",
    "    \n",
    "    def backward(self,dout=1):\n",
    "        batch_size=self.t.shape[0]\n",
    "        dx=(self.y-self.t)/batch_size\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.7誤差逆伝播法の実装\n",
    "#5.7.2誤差逆伝播法に対応したニューラルネットワークの実装\n",
    "import sys,os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from common.layers import *\n",
    "from common.gradient import numerical_gradient\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNet:\n",
    "    def __init__(self,input_size,hidden_size,output_size,weight_init_std=0.01):\n",
    "        #重み\n",
    "        self.params={}\n",
    "        self.params['W1']=weight_init_std*np.random.randn(input_size,hidden_size)\n",
    "        self.params['b1']=np.zeros(hidden_size)\n",
    "        self.params['W2']=weight_init_std*np.random.randn(hidden_size,output_size)\n",
    "        self.params['b2']=np.zeros(output_size)\n",
    "        \n",
    "        #レイヤの生成\n",
    "        self.layers=OrderedDict()\n",
    "        self.layers['Affine1']=Affine(self.params['W1'],self.params['b1'])\n",
    "        self.layers['Affine2']=Affine(self.params['W2'],self.params['b2'])\n",
    "        \n",
    "        self.lastLayer=SoftmaxWithLoss()\n",
    "        \n",
    "    def predict(self,x):\n",
    "        for layer in self.layers.values():\n",
    "            x=layer.forward(x)\n",
    "        return x\n",
    "    \n",
    "    #x:入力データ、t:教師データ\n",
    "    def loss(self,x,t):\n",
    "        y=self.predict(x)\n",
    "        return self.lastLayer.forward(y,t)\n",
    "    \n",
    "    def accuracy(self,x,t):\n",
    "        y=self.predict(x)\n",
    "        y=np.argmax(y,axis=1)\n",
    "        if t.ndim!=1:t=np.argmax(t,axis=1)\n",
    "        accuracy=np.sum(y==t)/float(x.shape[0])\n",
    "        return accuracy\n",
    "    \n",
    "    #x:入力データ、t:教師データ\n",
    "    def numerical_gradient(self,x,t):\n",
    "        loss_W=lambda W:self.loss(x,t)\n",
    "        \n",
    "        grads={}\n",
    "        grads['W1']=numerical_gradient(loss_W,self.params['W1'])\n",
    "        grads['b1']=numerical_gradient(loss_W,self.params['b1'])\n",
    "        grads['W2']=numerical_gradient(loss_W,self.params['W2'])\n",
    "        grads['b2']=numerical_gradient(loss_W,self.params['b2'])\n",
    "        return grads\n",
    "    \n",
    "    def gradient(self,x,t):\n",
    "        #forward\n",
    "        self.loss(x,t)\n",
    "        \n",
    "        #backward\n",
    "        dout=1\n",
    "        dout=self.lastLayer.backward(dout)\n",
    "        \n",
    "        layers=list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout=layer.backward(dout)\n",
    "            \n",
    "        #設定\n",
    "        grads={}\n",
    "        grads['W1']=self.layers['Affine1'].dW\n",
    "        grads['b1']=self.layers['Affine1'].db\n",
    "        grads['W2']=self.layers['Affine2'].dW\n",
    "        grads['b2']=self.layers['Affine1'].db\n",
    "        \n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.7.3誤差逆伝播法の勾配確認\n",
    "import sys,os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "from two_layer_net import TwoLayerNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading train-images-idx3-ubyte.gz ... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\nDownloading train-labels-idx1-ubyte.gz ... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\nDownloading t10k-images-idx3-ubyte.gz ... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\nDownloading t10k-labels-idx1-ubyte.gz ... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\nConverting train-images-idx3-ubyte.gz to NumPy Array ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\nConverting train-labels-idx1-ubyte.gz to NumPy Array ...\nDone\nConverting t10k-images-idx3-ubyte.gz to NumPy Array ...\nDone\nConverting t10k-labels-idx1-ubyte.gz to NumPy Array ...\nDone\nCreating pickle file ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (3,10) (3,) ",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-ac216e7b8fc0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mt_batch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mt_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mgrad_numerical\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumerical_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mgrad_backprop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\two_layer_net.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, x, t)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;31m# backward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[0mdy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbatch_num\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W2'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b2'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (3,10) (3,) "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "#でーたの読み込み\n",
    "(x_train,t_train),(x_test,t_test)=load_mnist(normalize=True)\n",
    "network=TwoLayerNet(input_size=784,hidden_size=50,output_size=10)\n",
    "x_batch=x_train[:3]\n",
    "t_batch=t_train[:3]\n",
    "grad_numerical=network.numerical_gradient(x_batch,t_batch)\n",
    "grad_backprop=network.gradient(x_batch,t_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-54-78ed222f605f>, line 2)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-54-78ed222f605f>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    for key in grad_numerical(np.abs(grad_backprop[key]-grad_numerical[key]))\u001b[0m\n\u001b[1;37m                                                                             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "#各重みの絶対誤差の平均を求める\n",
    "for key in grad_numerical(np.abs(grad_backprop[key]-grad_numerical[key]))\n",
    "    print(key+\":\"+str(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#誤差逆伝播法を使った学習\n",
    "import sys,os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "from two_layer_net import TwoLayerNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#データの読み込み\n",
    "(x_train,t_train),(x_test,t_test)=load_mnist(normalize=True,one_hot_label=True)\n",
    "\n",
    "network=TwoLayerNet(input_size=784,hidden_size=50,output_size=10)\n",
    "\n",
    "iters_num=10000\n",
    "train_size=x_train.shape[0]\n",
    "batch_size=100\n",
    "learning_rate=0.1\n",
    "train_loss_list=[]\n",
    "train_acc_list=[]\n",
    "test_acc_list=[]\n",
    "iter_per_epoch=max(train_size/batch_size,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09035 0.0892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7819333333333334 0.7861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8741666666666666 0.8763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8980166666666667 0.9005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9082333333333333 0.9103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9140333333333334 0.9157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9192833333333333 0.9194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9244 0.9252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9277333333333333 0.9299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.93095 0.9322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9349833333333334 0.9342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.93725 0.9384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9387666666666666 0.9399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9414833333333333 0.9421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.94365 0.9433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9452 0.9438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.94655 0.9453\n"
     ]
    }
   ],
   "source": [
    "for i in range(iters_num):\n",
    "    batch_mask=np.random.choice(train_size,batch_size)\n",
    "    x_batch=x_train[batch_mask]\n",
    "    t_batch=t_train[batch_mask]\n",
    "    \n",
    "    #誤差逆伝播法によって勾配を求める\n",
    "    grad=network.gradient(x_batch,t_batch)\n",
    "    \n",
    "    #更新\n",
    "    for key in ('W1','b1','W2','b2'):\n",
    "        network.params[key]-=learning_rate*grad[key]\n",
    "        \n",
    "    loss=network.loss(x_batch,t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    if i % iter_per_epoch==0:\n",
    "        train_acc=network.accuracy(x_train,t_train)\n",
    "        test_acc=network.accuracy(x_test,t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(train_acc,test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
